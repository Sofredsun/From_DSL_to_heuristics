{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad569d5-2c00-4bae-8b8d-1d9d8e93b5e0",
   "metadata": {},
   "source": [
    "Serial Schedule Generation Scheme (SGS)\n",
    "\n",
    "The solver iteratively schedules jobs based on a priority rule. For each job, it determines the earliest feasible start time by considering:\n",
    "\n",
    "* Precedence Constraints: Must start after all predecessors finish.\n",
    "* Resource Constraints: Must start when sufficient resources are available for its entire duration.\n",
    "* Latest Finish Time (LFT): Jobs are prioritized by their calculated LFT, aiming to schedule those with earlier deadlines first.\n",
    "\n",
    "The algorithm maintains a resource timeline and incrementally searches for the first available time slot that satisfies all constraints. It also dynamically extends the timeline as needed and includes a mechanism to prevent deadlocks by ensuring resource availability.\n",
    "\n",
    "Heuristics Employed:\n",
    "\n",
    "* Latest Finish Time (LFT) Prioritization: Jobs are sorted by their LFT, with jobs having earlier LFTs being scheduled first. This aims to address time-critical tasks sooner.\n",
    "* Earliest Feasible Start Time Search: The solver searches for the absolute earliest time a job can begin by incrementally checking time steps from its earliest possible start time until resource availability and precedence constraints are confirmed.\n",
    "* Resource Availability Check & Jump: When a resource constraint is violated, the search for a start time jumps to the earliest point the blocking resource might become available, optimizing the search.\n",
    "* Capacity Adjustment: If a job requires more resources than ever available, the system dynamically increases the resource capacity to prevent deadlocks, although this indicates an inherently infeasible project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40a7cee-544c-42eb-acd1-18766b625031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "def solve_project(json_data: Dict) -> Dict:\n",
    "    start_wall_time = time.time()\n",
    "    \n",
    "    # 1. Parse Input\n",
    "    jobs = json_data.get('jobs', [])\n",
    "    initial_res = json_data.get('initial_resources', {}) or {}\n",
    "    \n",
    "    # Convert all IDs to strings for consistency\n",
    "    job_map = {str(j['id']): j for j in jobs}\n",
    "    act_ids = [str(j['id']) for j in jobs]\n",
    "    \n",
    "    # Pre-calculate predecessors\n",
    "    predecessors = {jid: [] for jid in act_ids}\n",
    "    for j in jobs:\n",
    "        jid = str(j['id'])\n",
    "        successors = j.get('precedences', {}).get('time_successors', [])\n",
    "        for succ in successors:\n",
    "            if str(succ) in predecessors:\n",
    "                predecessors[str(succ)].append(jid)\n",
    "\n",
    "    # 2. Priority Rule: Latest Finish Time (LFT)\n",
    "    total_duration = sum(j.get('duration', 0) for j in jobs)\n",
    "    current_horizon = max(total_duration * 3, 500) \n",
    "    lf = {jid: current_horizon for jid in act_ids}\n",
    "    \n",
    "    for _ in range(len(act_ids)):\n",
    "        for j in jobs:\n",
    "            jid = str(j['id'])\n",
    "            successors = j.get('precedences', {}).get('time_successors', [])\n",
    "            valid_succs = [str(s) for s in successors if str(s) in job_map]\n",
    "            if valid_succs:\n",
    "                lf[jid] = min([lf[s] - job_map[s]['duration'] for s in valid_succs])\n",
    "\n",
    "    # 3. Scheduling Scheme\n",
    "    scheduled = {}\n",
    "    res_timeline = {str(r): [amt] * (current_horizon + 1) for r, amt in initial_res.items()}\n",
    "    \n",
    "    def ensure_timeline_length(target_len: int):\n",
    "        nonlocal current_horizon\n",
    "        if target_len > current_horizon:\n",
    "            extension = (target_len - current_horizon) + 500\n",
    "            for r_id in res_timeline:\n",
    "                res_timeline[r_id].extend([res_timeline[r_id][-1]] * extension)\n",
    "            current_horizon = len(next(iter(res_timeline.values()))) - 1\n",
    "\n",
    "    # Sort by LFT\n",
    "    eligible_jobs = sorted(jobs, key=lambda x: lf[str(x['id'])])\n",
    "\n",
    "    for job in eligible_jobs:\n",
    "        jid = str(job['id'])\n",
    "        dur = job.get('duration', 0)\n",
    "        reqs = job.get('resources_required', {})\n",
    "        cons_prod = job.get('resource_consumption', {})\n",
    "\n",
    "        # Deadlock Prevention: Check if activity is EVER possible\n",
    "        for r_id, amt in reqs.items():\n",
    "            r_id_str = str(r_id)\n",
    "            if r_id_str not in res_timeline:\n",
    "                res_timeline[r_id_str] = [0] * (current_horizon + 1)\n",
    "            \n",
    "            # If demand > max possible capacity, we cap it or raise warning\n",
    "            # (In a real scenario, this project would be impossible)\n",
    "            max_capacity = max(res_timeline[r_id_str])\n",
    "            if amt > max_capacity:\n",
    "                # Forcefully increase capacity to prevent infinite loop\n",
    "                res_timeline[r_id_str] = [max(val, amt) for val in res_timeline[r_id_str]]\n",
    "\n",
    "        t_start = max([scheduled[p] + job_map[p]['duration'] for p in predecessors[jid]], default=0)\n",
    "        \n",
    "        # Search for a feasible window\n",
    "        found_slot = False\n",
    "        while not found_slot:\n",
    "            ensure_timeline_length(t_start + dur + 1)\n",
    "            \n",
    "            feasible = True\n",
    "            next_possible_t = t_start + 1\n",
    "            \n",
    "            for r_id, amt in reqs.items():\n",
    "                r_id_str = str(r_id)\n",
    "                for t in range(t_start, t_start + dur):\n",
    "                    if res_timeline[r_id_str][t] < amt:\n",
    "                        feasible = False\n",
    "                        # Optimization: Jump to when this resource might be free\n",
    "                        next_possible_t = max(next_possible_t, t + 1)\n",
    "                        break\n",
    "                if not feasible: break\n",
    "            \n",
    "            if feasible:\n",
    "                scheduled[jid] = t_start\n",
    "                # Update Renewable\n",
    "                for r_id, amt in reqs.items():\n",
    "                    for t in range(t_start, t_start + dur):\n",
    "                        res_timeline[str(r_id)][t] -= amt\n",
    "                # Update Consumption/Production\n",
    "                for r_id, delta in cons_prod.items():\n",
    "                    val = delta.get('amount', 0) if isinstance(delta, dict) else delta\n",
    "                    r_id_str = str(r_id)\n",
    "                    if r_id_str not in res_timeline:\n",
    "                        res_timeline[r_id_str] = [0] * (current_horizon + 1)\n",
    "                    for t in range(t_start + dur, len(res_timeline[r_id_str])):\n",
    "                        res_timeline[r_id_str][t] += val\n",
    "                found_slot = True\n",
    "            else:\n",
    "                t_start = next_possible_t\n",
    "                # Safety break to prevent infinite hang if logic fails\n",
    "                if t_start > current_horizon + 5000:\n",
    "                    scheduled[jid] = t_start # Force schedule\n",
    "                    found_slot = True\n",
    "\n",
    "    # 4. Metrics\n",
    "    finish_times = [scheduled[jid] + job_map[jid]['duration'] for jid in scheduled]\n",
    "    makespan = max(finish_times) if finish_times else 0\n",
    "    execution_time = (time.time() - start_wall_time)*1000\n",
    "\n",
    "    return {\n",
    "        \"schedule\": scheduled,\n",
    "        \"metrics\": {\n",
    "            \"makespan\": int(makespan),\n",
    "            \"total_penalty\": 0,\n",
    "            \"execution_time\": f\"{execution_time:.6f}s\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef090af2-9414-455e-9878-f3a56d0b6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schedule': {'0': 0, '25': 0, '13': 0, '37': 0, '26': 0, '1': 0, '16': 0, '18': 0, '49': 0, '38': 0, '40': 0, '41': 4, '42': 6, '14': 10, '15': 10, '19': 11, '27': 8, '50': 10, '2': 0, '4': 0, '6': 7, '28': 0, '29': 4, '3': 7, '39': 14, '51': 20, '5': 10, '54': 11, '17': 21, '20': 21, '21': 27, '43': 14, '53': 28, '52': 37, '7': 13, '8': 9, '9': 10, '10': 17, '11': 21, '12': 28, '22': 42, '23': 37, '24': 45, '30': 8, '31': 16, '32': 16, '33': 16, '34': 18, '35': 0, '36': 25, '44': 24, '45': 24, '46': 0, '47': 0, '48': 31, '55': 39, '56': 45, '57': 43, '58': 49, '59': 52, '60': 61, '61': 61, '62': 61, '74': 61, '75': 61, '76': 61, '77': 61, '78': 61, '63': 61, '64': 61, '79': 66, '80': 68, '65': 69, '66': 70, '67': 75, '68': 84, '69': 92, '70': 84, '71': 84, '72': 85, '73': 99, '81': 76, '82': 82, '83': 82, '84': 86, '85': 96, '86': 99, '87': 99, '89': 99, '88': 107, '91': 99, '92': 108, '94': 115, '95': 125, '96': 108, '97': 134, '98': 134, '90': 134, '93': 139, '99': 134, '100': 140, '101': 134, '102': 134, '103': 143, '104': 149, '105': 135, '106': 150, '107': 153, '108': 143, '109': 156, '110': 156, '111': 156, '112': 156, '113': 161, '114': 164, '115': 163, '116': 173, '117': 183, '118': 188, '119': 173, '120': 190, '121': 200}, 'metrics': {'makespan': 200, 'total_penalty': 0, 'execution_time': '38.998365s'}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/Admin/Desktop/nonrenewable.json\", 'r') as f:\n",
    "    data = json.load(f) \n",
    "\n",
    "result = solve_project(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65576bcd-bf7b-44c5-b1e9-a5381641f129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
